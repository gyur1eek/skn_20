{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095541c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가우스 잡음 추가  함수\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "#가우스 노이즈\n",
    "# noisy_pixel = original_pixel +N(u=0, e = scale)\n",
    "# 평균을 0으로 만듦: 픽셀을 전체적으로 밝히거나 어둡게 하지 않음\n",
    "# 표준편차: sacler -> 값이 클수록 노이즈가 강해짐\n",
    "# 0.8 -> 노이즈의 양  많고.. 숫자 일부를 흐릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c866eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.0305435 , 0.        , 0.        ,\n",
       "         0.6676615 , 0.        , 0.        , 0.84042013, 0.77994277,\n",
       "         0.4083756 , 0.13666231, 0.        , 0.31951874, 0.        ,\n",
       "         0.16082849, 0.        , 0.13052608, 0.31890214, 0.20509157,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.42385755, 0.        ],\n",
       "        [0.        , 1.        , 0.14707788, 0.4176176 , 0.        ,\n",
       "         0.86150632, 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.26319405,\n",
       "         0.        , 0.92226462, 0.20723772, 1.        , 0.        ,\n",
       "         0.82229336, 1.        , 0.        , 0.        , 0.4116074 ,\n",
       "         0.        , 0.06912519, 0.96645385],\n",
       "        [0.74975139, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.19508304, 0.43521989, 0.38223297, 0.52319323, 0.08165543,\n",
       "         0.42981172, 0.24957665, 0.79407172, 0.        , 0.87913035,\n",
       "         0.42650427, 0.6208332 , 0.        , 0.90462668, 1.        ,\n",
       "         0.        , 0.34183827, 0.        , 0.        , 0.11970806,\n",
       "         0.        , 0.13992044, 0.38531622],\n",
       "        [1.        , 0.06226659, 0.        , 0.11889908, 0.        ,\n",
       "         0.20688107, 0.66148901, 0.08039162, 0.        , 0.        ,\n",
       "         0.27838536, 0.29911842, 0.        , 0.19427839, 0.00386532,\n",
       "         0.        , 0.        , 0.65415866, 0.40734575, 0.        ,\n",
       "         0.        , 0.31304832, 0.        , 0.        , 0.59414553,\n",
       "         0.        , 0.37261106, 0.09697012],\n",
       "        [0.1997857 , 0.        , 1.        , 0.20286303, 0.79689881,\n",
       "         0.        , 0.16055318, 0.3366682 , 0.68228005, 0.1507722 ,\n",
       "         0.        , 0.        , 0.48423031, 0.89528823, 0.71574953,\n",
       "         0.        , 0.        , 1.        , 0.0862541 , 0.69392169,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.73552893,\n",
       "         0.24911155, 0.        , 0.        ],\n",
       "        [1.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "         0.65987995, 0.        , 0.15047112, 0.53531721, 0.        ,\n",
       "         0.4531207 , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.36144533, 0.        , 0.30931391, 0.04399814, 0.        ,\n",
       "         0.63836284, 0.54946119, 0.21424979, 0.8004318 , 0.25429723,\n",
       "         0.        , 1.        , 0.        ],\n",
       "        [1.        , 0.71856923, 0.02231602, 0.        , 0.06486635,\n",
       "         0.        , 0.88315028, 0.        , 1.        , 0.64975405,\n",
       "         0.3314016 , 0.5303815 , 0.08064831, 0.        , 0.03570293,\n",
       "         0.        , 0.        , 0.25632975, 0.        , 0.13780614,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.78278397],\n",
       "        [0.61309772, 0.07063549, 0.        , 0.66903024, 0.22857434,\n",
       "         1.        , 0.97693841, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.40077715, 0.05396178, 0.        , 1.        ,\n",
       "         0.98370211, 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.        , 0.32466369, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.17191113, 1.        , 0.        , 0.71212989,\n",
       "         0.74234068, 0.29514046, 0.        , 0.84871383, 0.        ,\n",
       "         0.84030495, 0.52330352, 0.        , 0.6040436 , 0.        ,\n",
       "         0.42878443, 0.        , 0.        , 0.72262529, 0.        ,\n",
       "         0.76742505, 0.        , 0.        , 0.        , 0.99271587,\n",
       "         1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.48155473, 0.        ,\n",
       "         1.        , 0.19265004, 0.        , 0.54397763, 0.        ,\n",
       "         0.80210713, 0.        , 0.        , 0.        , 0.14619089,\n",
       "         0.64424787, 0.        , 0.52456087, 0.09536508, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.04833464, 0.05552561, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.00400844,\n",
       "         0.86538612, 0.71111283, 1.        , 0.33356594, 0.        ,\n",
       "         1.        , 0.        , 0.        , 0.02932689, 0.        ,\n",
       "         1.        , 0.39171747, 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.11682804, 0.38186123, 0.        , 0.18771885,\n",
       "         0.79610979, 0.28313331, 0.43023616],\n",
       "        [0.77836844, 0.        , 0.        , 1.        , 0.46931902,\n",
       "         1.        , 0.12907007, 0.        , 0.49491744, 0.67325837,\n",
       "         0.78085825, 0.        , 0.        , 0.70570148, 0.79785297,\n",
       "         0.        , 0.        , 0.4961857 , 0.        , 0.80629164,\n",
       "         0.        , 0.        , 0.60887565, 1.        , 0.26201815,\n",
       "         0.        , 0.        , 0.07565932],\n",
       "        [1.        , 1.        , 0.36976288, 0.60043642, 0.        ,\n",
       "         0.        , 1.        , 0.        , 0.82695456, 0.        ,\n",
       "         0.        , 0.61087806, 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.25625682,\n",
       "         0.48390891, 0.        , 0.        , 0.08678421, 0.        ,\n",
       "         0.        , 1.        , 0.        ],\n",
       "        [0.        , 0.03547069, 0.        , 0.20509689, 0.        ,\n",
       "         0.05016029, 0.        , 0.55294759, 1.        , 0.        ,\n",
       "         0.        , 0.0841874 , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.2424359 , 0.31034183, 0.        , 0.62103375,\n",
       "         0.37527863, 0.        , 0.75154967, 0.        , 0.45576531,\n",
       "         0.27661755, 1.        , 0.60555828],\n",
       "        [0.69191051, 0.65977996, 0.28844085, 0.42297581, 0.        ,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.07307465,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.53851422,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "         0.05809099, 0.58323121, 0.        ],\n",
       "        [0.45853485, 0.65754055, 0.10844641, 0.        , 0.14246245,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "         0.64362205, 0.07764752, 0.        , 0.22790853, 0.        ,\n",
       "         0.53419996, 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "         0.13829447, 1.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.        , 0.28874967, 0.        ,\n",
       "         0.19666908, 0.39459689, 0.66890731, 0.34747318, 0.        ,\n",
       "         0.74309085, 1.        , 0.27680761, 0.19334869, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.83943374,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.36671392, 0.63526185, 0.        , 1.        ,\n",
       "         0.42382168, 0.61849023, 0.37022266, 0.        , 0.75372596,\n",
       "         0.34804761, 0.60312168, 0.        , 0.        , 0.16450953,\n",
       "         0.25599484, 0.14395528, 0.89707506, 0.        , 0.48974694,\n",
       "         0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.        , 0.        , 0.52097782,\n",
       "         0.        , 0.        , 0.        , 0.10108601, 0.61264075,\n",
       "         0.        , 0.16195067, 0.38951659, 0.51319502, 0.        ,\n",
       "         0.49283472, 0.13973988, 0.78973455, 0.        , 0.16704537,\n",
       "         1.        , 1.        , 0.18742468, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , 0.68687319, 0.        ,\n",
       "         0.1436189 , 0.90244848, 0.        , 0.49639512, 0.        ,\n",
       "         0.        , 0.        , 0.        , 1.        , 0.1907984 ,\n",
       "         0.43073755, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.17785163, 0.33199418, 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.88257481],\n",
       "        [0.        , 0.        , 0.        , 0.65725243, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.81195107, 0.        , 0.        , 0.24904561, 0.        ,\n",
       "         0.75963522, 0.68448407, 0.68188538, 0.08979252, 0.        ,\n",
       "         0.02299827, 1.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.28586566, 0.        , 0.        ,\n",
       "         0.23400186, 0.20883507, 0.        , 0.81650311, 0.        ,\n",
       "         0.1664383 , 0.50346348, 0.34559466, 0.32102359, 0.52332011,\n",
       "         1.        , 0.        , 0.        , 0.19190896, 0.        ,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.05924708,\n",
       "         0.        , 0.13908019, 0.58349745],\n",
       "        [0.        , 1.        , 0.23743118, 1.        , 0.49972547,\n",
       "         0.58684216, 0.74566649, 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.78811985, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.03884165, 0.49282424, 0.        , 0.        ,\n",
       "         0.35990972, 0.        , 0.        , 0.62463743, 0.92005456,\n",
       "         0.        , 1.        , 0.62265675],\n",
       "        [0.        , 0.        , 0.74856834, 1.        , 0.        ,\n",
       "         0.5551687 , 0.        , 0.        , 0.28575018, 0.        ,\n",
       "         0.61427615, 0.        , 0.56036086, 0.        , 0.        ,\n",
       "         0.50141306, 0.        , 0.        , 0.        , 0.55109896,\n",
       "         0.08614032, 0.50810609, 0.        , 0.        , 0.        ,\n",
       "         0.86737677, 1.        , 0.70433635],\n",
       "        [0.        , 0.        , 0.        , 0.08350769, 0.        ,\n",
       "         0.23371181, 0.70039882, 0.68360938, 0.61186163, 1.        ,\n",
       "         0.        , 0.67029777, 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.5124402 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.61276398, 0.76010485,\n",
       "         0.47218814, 0.        , 0.        , 0.        , 0.27993132,\n",
       "         0.        , 0.        , 0.43182424, 0.34915309, 0.        ,\n",
       "         0.14837935, 0.06576996, 0.        , 0.13692223, 0.2953764 ,\n",
       "         1.        , 0.26345927, 0.30231939, 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.09500478],\n",
       "        [0.        , 0.        , 0.51510184, 0.        , 0.86076779,\n",
       "         0.        , 1.        , 0.        , 0.20448663, 0.        ,\n",
       "         0.        , 0.        , 0.17224843, 0.        , 0.        ,\n",
       "         0.        , 0.32555156, 0.        , 0.        , 1.        ,\n",
       "         0.65868436, 0.        , 0.27979665, 0.40769426, 0.75280294,\n",
       "         0.01457978, 0.        , 0.        ],\n",
       "        [0.03079256, 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.87092869, 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.30367999, 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.        , 0.60478694, 0.        ,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.03604644,\n",
       "         0.        , 0.53689328, 0.98112385]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "gaussian_data_X = np.random.normal(\n",
    "        loc =0, scale =0.8, size=(1,28,28)\n",
    "    ) \n",
    "gaussian_data_X.shape\n",
    "np.clip(gaussian_data_X,0,1)\n",
    "# np.clip(gaussian_data_X,0.1)\n",
    "#오류의 이유 a_max가 필요하다 ,이지 .을 사용하는 거는 아님\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea657899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(X, scale=0.8):\n",
    "    gaussian_data_X =X + np.random.normal(\n",
    "        loc =0, scale =scale, size=X.shape \n",
    "    ) \n",
    "    gaussian_data_X = np.clip(gaussian_data_X,0,1)#이미지픽셀의 값을 0과 1사이로 정규화\n",
    "    gaussian_data_X = torch.tensor(gaussian_data_X,dtype= torch.float32)\n",
    "    return gaussian_data_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eaf1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습데이터 정의\n",
    "training_data = MNIST(root='./', train=True,download=True,transform=ToTensor())\n",
    "test_data = MNIST(root='./', train=False,download=True,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "332d7bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata2\\AppData\\Local\\Temp\\ipykernel_1644\\2868163305.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gaussian_data_X =X + np.random.normal(\n",
      "C:\\Users\\Playdata2\\AppData\\Local\\Temp\\ipykernel_1644\\2868163305.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gaussian_data_X = torch.tensor(gaussian_data_X,dtype= torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fee3df7b20>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(training_data))\n",
    "gaussian = gaussian_noise(img)\n",
    "img = img.permute(1,2,0)\n",
    "gaussian = gaussian.permute(1,2,0)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(gaussian, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3ffe8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata2\\AppData\\Local\\Temp\\ipykernel_1644\\2868163305.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gaussian_data_X =X + np.random.normal(\n",
      "C:\\Users\\Playdata2\\AppData\\Local\\Temp\\ipykernel_1644\\2868163305.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gaussian_data_X = torch.tensor(gaussian_data_X,dtype= torch.float32)\n"
     ]
    }
   ],
   "source": [
    "for data, label in training_data:\n",
    "    noisy = gaussian_noise(data)\n",
    "    print(type(noisy), noisy.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습용 데이터셋\n",
    "from torch.utils.data.dataset import Dataset\n",
    "class Denoise(Dataset):\n",
    "    def __init__(self):\n",
    "        self.mnist = MNIST(root='./', train=True,download=True,transform=ToTensor())\n",
    "        self.data = []\n",
    "        #잡음 입히기\n",
    "        for data, label in self.mnist:\n",
    "            noisy = gaussian_noise(data) #0~1사이로 맞춤\n",
    "            self.data.append(noisy.unsqueeze((0))) #(1,1,28,28)\n",
    "        # for i in range(self.mnist.data.size()[0]):\n",
    "        #     gaussian_noise(self.mnist.data[i])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.mnist.dat[index] / 255 #원본이미지로 0~1 표준화 정규화\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34c2e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 기본 블럭\n",
    "import torch.nn as nn\n",
    "#conv-relu-conv-relu\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,in_channel, out_channel,hidden_channel):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, hidden_channel, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channel, out_channel, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb780e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 28, 28])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data= torch.randn(1,1,28,28)\n",
    "sample_model = BasicBlock(1,20,10)\n",
    "sample_model(sample_data).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4a59b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.conv1 = BasicBlock(1,16,16)\n",
    "        self.conv2 = BasicBlock(16,8,8)\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "    def forward(self,X):\n",
    "        X = self.pool(self.conv1(X)) #(1,16,14,14)\n",
    "        out = self.pool(self.conv2(X)) # 1, 8,7,7\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = torch.randn(1,1,28,28)\n",
    "temp_encoder = Encoder()\n",
    "result_encoder = temp_encoder(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82644811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.conv1 = BasicBlock(8,8,8)\n",
    "        self.conv2 = BasicBlock(8,16,16)\n",
    "        # 출력층\n",
    "        self.conv3 = nn.Conv2d(16,1,kernel_size=3, padding=1)\n",
    "        #업셈플링 총\n",
    "        self.upsampling1 = nn.ConvTranspose2d(8,8,kernel_size=2, stride=2)\n",
    "        self.upsampling2 = nn.ConvTranspose2d(16,16,kernel_size=2, stride=2)\n",
    "    def forward(self,X):\n",
    "        X = self.upsampling1(self.conv1(X))\n",
    "        X = self.upsampling2(self.conv2(X))\n",
    "        out = self.conv3(X)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0328d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Decoder()\n",
    "d(result_encoder).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "754c171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAE 오토인코더\n",
    "# 인코더와 디코더를 연결: 인코더의 출력을 디코더의 입력으로 제공\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CAE,self).__init__()\n",
    "        self.enc = Encoder()\n",
    "        self.dec = Decoder()\n",
    "    def forward(self,X):\n",
    "        X= self.enc(X)\n",
    "        X= self.dec(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479362d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48f38c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata2\\AppData\\Local\\Temp\\ipykernel_1644\\2868163305.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gaussian_data_X =X + np.random.normal(\n",
      "C:\\Users\\Playdata2\\AppData\\Local\\Temp\\ipykernel_1644\\2868163305.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gaussian_data_X = torch.tensor(gaussian_data_X,dtype= torch.float32)\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MNIST' object has no attribute 'dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m     13\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(train_loader)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, label \u001b[38;5;129;01min\u001b[39;00m loop:\n\u001b[0;32m     15\u001b[0m     data,label \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(data)\n",
      "File \u001b[1;32mc:\\Users\\Playdata2\\miniconda3\\envs\\deep\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Playdata2\\miniconda3\\envs\\deep\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    738\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Playdata2\\miniconda3\\envs\\deep\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Playdata2\\miniconda3\\envs\\deep\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Playdata2\\miniconda3\\envs\\deep\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[31], line 17\u001b[0m, in \u001b[0;36mDenoise.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m     16\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]\n\u001b[1;32m---> 17\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmnist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdat\u001b[49m[index] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MNIST' object has no attribute 'dat'"
     ]
    }
   ],
   "source": [
    "#모델 학습\n",
    "from tqdm import tqdm\n",
    "from torch.optim.adam import Adam\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim.adam import Adam\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "train_dataset = Denoise()\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "model = CAE().to(device)\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "loop = tqdm(train_loader)\n",
    "for data, label in loop:\n",
    "    data,label = data.to(device), label.to(device)\n",
    "    pred = model(data)\n",
    "    loss = criterion(pred,label)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    loop.set_postfix({'loss': f'{loss.item():.4f}'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
